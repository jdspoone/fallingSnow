\documentclass[conference]{acmsiggraph}

\title{Real-time Rendering of Falling Snow}

\author{Brent Glowinski, Jeff Spooner, and Parker Fish}
\pdfauthor{The above}

\keywords{snow, real-time, fog, particles}

\begin{document}

\maketitle

\begin{abstract}

Abstract goes here.

\end{abstract}

\keywordlist

\copyrightspace

\section{Introduction and Motivation}
Blah blah blah boring things.

\section{Methodology}
Slightly more interesting things? Formulae go here.

\section{Implementation}

\subsection{Particle Model}
For a simulation of falling snow to approach realism, individual snowflakes must have independent and variable velocities. While it is possible to model this entirely on the CPU, this approach quickly becomes infeasible as the number of snowflakes increases. This, along with the fact that the position and velocity attributes of a given particle are independent of those of all others, makes the GPU the ideal place to implement a particle model.

The particle model used in this project was implemented by way of OpenGL's \textit{transform feedback} functionality, which allows for general purpose computation to be outsourced to the GPU. During \textit{transform feedback}, a shader program will write one or more of its output variables into a vertex buffer object (henceforth referred to as a \textit{VBO}). Our implementation included a dedicated transform feedback shader program, with the sole purpose of updating the positions, velocities and rotation angles of snowflakes, 

After compiling the necessary shader files, but before linking the program the feedback varyings must be specified using the \textit{glTransformFeedbackVaryings} method. This is where we specify, as an array of strings, the labels of the output variables we wish to write to \textit{VBOs}. In the case of this project, they are \textit{nextPosition, nextVelocity} and \textit{nextAngle}. Additionally, we must specify whether we wish the output to be written to separate \textit{VBOs}, or interleaved on a single \textit{VBO}, using \textit{GL\_SEPARATE\_ATTRIBS} or \textit{GL\_INTERLEAVED\_ATTRIBS} respectively. After this, linking the program occurs.

For each of the vertex attributes we wish to continually update on the GPU, there are two \textit{VBOs}, specifically \textit{positionVBO[2]}, \textit{velocityVBO[2]} and \textit{angleVBO[2]}. Each time \textit{transform feedback} is performed, the input vertex attributes will be bound from the \textit{VBOs} at index \textit{iteration \% 2}, where \textit{iteration} is the number of times the rendering loop has run. Then, the feedback varyings will be written out to the \textit{VBOs} at index \textit{(iteration + 1) \% 2}. The output buffers are specified using the \textit{glBindBufferBase} method. Finally, after \textit{transform feedback} is performed, the pointers to various \textit{VBOs} are swapped, for instance \textit{swap(positionVBO[0], positionVBO[1])}.

\subsection{Perlin Wind}
While a full fluid dynamics simulation is required for the most accurate results in modelling the movement of snowflakes, it is far too slow to use for an extremely large system. Instead, a 3D texture is generated before simulation starts to determine each particle's velocity as it moves through the scene.

We start by defining a 3D array of size 256 in each dimension. This is the lowest resolution texture we could generate that still gave us reasonably varied movement with our snowflakes; lower resolutions tended to result in more predictable but less interesting movement of snowflakes. Each element of this array is initialized to three randomized float values, \textit{x}, \textit{y}, and \textit{z}. These values are generated using the standard \textit{rand()} function in the range of [0..1] then adjusted as desired: \textit{x} is made negative to go to the left, \textit{y} is halved to make snowflakes fall slower, and \textit{z} has 0.5 subtracted from it to put it in the range of [-0.5..0.5], thus allowing it to move back and forth.

Turbulence is then applied to the texture by taking several ``zoomed in'' versions of the random array, smoothing over them using a bilinear filter, and adding them together. To elaborate, we iterate over the array and, for each cell, we take three zoom-levels of the texture by simply dividing the index by a factor of two at each level. Since this returns a floating point value, we interpolate between the nearest integer coordinates to determine the value of the array at that point. Adding these interpolated values together, with the more zoomed-in values given more weight, gives us the final texture. This texture is stored in a separate array since storing them back into the original array results in all the values blending together due to the filtering.

The final 3D texture is passed into the transform feedback shader. Each particle uses its position - normalized to the range of [0..1] -  as an index to get a velocity. This velocity is then mixed with a downward velocity by an amount based on the particle's index. This causes some particles to follow the texture more closely than others, providing more variance between their movements and less banding when they follow the same path. To get the next position, we simply subtract this mixed velocity from the previous position.

\subsection{Fog Aggregation}
I'm not actually sure, just here because it's probably important enough for a subsection.

\section{Results}
Look cool.

\section{Conclusion}
Finished! Huzzah!

\bibliographystyle{acmsiggraph}
\nocite{*}
\bibliography{template}
\end{document}
